icmp6_send_response_with_addrs_and_netif (struct pbuf * p, u8_t code, u32_t data, u8_t type, const struct ip6_addr_t * reply_src, const struct ip6_addr_t * reply_dest, struct netif * netif)
{
  err_t res;
  u16_t len;
  u16_t offset;
  u16_t datalen;
  struct icmp6_hdr * icmp6hdr;
  struct pbuf * q;

  <bb 2> :
  _1 = p->tot_len;
  datalen = MIN_EXPR <_1, 1232>;
  _2 = datalen + 8;
  q = pbuf_alloc (54, _2, 640);
  if (q == 0B)
    goto <bb 3>; [INV]
  else
    goto <bb 4>; [INV]

  <bb 3> :
  _3 = lwip_stats.icmp6.memerr;
  _4 = _3 + 1;
  lwip_stats.icmp6.memerr = _4;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 13>; [INV]

  <bb 4> :
  _5 = q->len;
  if (_5 <= 7)
    goto <bb 5>; [INV]
  else
    goto <bb 6>; [INV]

  <bb 5> :
  __asm__ __volatile__("BKPT #0
	");
  goto <bb 5>; [INV]

  <bb 6> :
  icmp6hdr = q->payload;
  icmp6hdr->type = type;
  icmp6hdr->code = code;
  _6 = lwip_htonl (data);
  icmp6hdr->data = _6;
  offset = 8;
  goto <bb 10>; [INV]

  <bb 7> :
  _7 = p->len;
  len = MIN_EXPR <datalen, _7>;
  _8 = p->payload;
  res = pbuf_take_at (q, _8, len, offset);
  if (res != 0)
    goto <bb 8>; [INV]
  else
    goto <bb 9>; [INV]

  <bb 8> :
  goto <bb 12>; [INV]

  <bb 9> :
  datalen = datalen - len;
  offset = offset + len;
  p = p->next;

  <bb 10> :
  if (p != 0B)
    goto <bb 11>; [INV]
  else
    goto <bb 12>; [INV]

  <bb 11> :
  if (datalen != 0)
    goto <bb 7>; [INV]
  else
    goto <bb 12>; [INV]

  <bb 12> :
  icmp6hdr->chksum = 0;
  _9 = q->tot_len;
  _10 = ip6_chksum_pseudo (q, 58, _9, reply_src, reply_dest);
  icmp6hdr->chksum = _10;
  _11 = lwip_stats.icmp6.xmit;
  _12 = _11 + 1;
  lwip_stats.icmp6.xmit = _12;
  ip6_output_if (q, reply_src, reply_dest, 255, 0, 58, netif);
  pbuf_free (q);

  <bb 13> :
<L11>:
  return;

}


icmp6_send_response_with_addrs (struct pbuf * p, u8_t code, u32_t data, u8_t type, const struct ip6_addr_t * src_addr, const struct ip6_addr_t * dest_addr)
{
  struct netif * netif;
  const struct ip6_addr * reply_dest;
  const struct ip6_addr * reply_src;

  <bb 2> :
  if (src_addr == 0B)
    goto <bb 3>; [INV]
  else
    goto <bb 4>; [INV]

  <bb 3> :
  __asm__ __volatile__("BKPT #0
	");
  goto <bb 3>; [INV]

  <bb 4> :
  if (dest_addr == 0B)
    goto <bb 5>; [INV]
  else
    goto <bb 6>; [INV]

  <bb 5> :
  __asm__ __volatile__("BKPT #0
	");
  goto <bb 5>; [INV]

  <bb 6> :
  reply_dest = src_addr;
  reply_src = dest_addr;
  netif = ip6_route (reply_src, reply_dest);
  if (netif == 0B)
    goto <bb 7>; [INV]
  else
    goto <bb 8>; [INV]

  <bb 7> :
  _1 = lwip_stats.icmp6.rterr;
  _2 = _1 + 1;
  lwip_stats.icmp6.rterr = _2;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 9>; [INV]

  <bb 8> :
  icmp6_send_response_with_addrs_and_netif (p, code, data, type, reply_src, reply_dest, netif);

  <bb 9> :
<L8>:
  return;

}


icmp6_send_response (struct pbuf * p, u8_t code, u32_t data, u8_t type)
{
  struct netif * netif;
  const struct ip6_addr * reply_dest;
  const struct ip6_addr * reply_src;

  <bb 2> :
  netif = ip_data.current_netif;
  if (netif == 0B)
    goto <bb 3>; [INV]
  else
    goto <bb 4>; [INV]

  <bb 3> :
  __asm__ __volatile__("BKPT #0
	");
  goto <bb 3>; [INV]

  <bb 4> :
  reply_dest = &ip_data.current_iphdr_src.u_addr.ip6;
  _1 = ip6_select_source_address (netif, reply_dest);
  reply_src = &_1->u_addr.ip6;
  if (reply_src == 0B)
    goto <bb 5>; [INV]
  else
    goto <bb 6>; [INV]

  <bb 5> :
  _2 = lwip_stats.icmp6.rterr;
  _3 = _2 + 1;
  lwip_stats.icmp6.rterr = _3;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 7>; [INV]

  <bb 6> :
  icmp6_send_response_with_addrs_and_netif (p, code, data, type, reply_src, reply_dest, netif);

  <bb 7> :
<L5>:
  return;

}


icmp6_param_problem (struct pbuf * p, icmp6_pp_code c, const void * pointer)
{
  u32_t pointer_u32;

  <bb 2> :
  _1 = ip_data.current_ip6_header;
  _2 = pointer - _1;
  pointer_u32 = (u32_t) _2;
  _3 = (unsigned char) c;
  icmp6_send_response (p, _3, pointer_u32, 4);
  return;

}


icmp6_time_exceeded_with_addrs (struct pbuf * p, icmp6_te_code c, const struct ip6_addr_t * src_addr, const struct ip6_addr_t * dest_addr)
{
  <bb 2> :
  _1 = (unsigned char) c;
  icmp6_send_response_with_addrs (p, _1, 0, 3, src_addr, dest_addr);
  return;

}


icmp6_time_exceeded (struct pbuf * p, icmp6_te_code c)
{
  <bb 2> :
  _1 = (unsigned char) c;
  icmp6_send_response (p, _1, 0, 3);
  return;

}


icmp6_packet_too_big (struct pbuf * p, u32_t mtu)
{
  <bb 2> :
  icmp6_send_response (p, 0, mtu, 2);
  return;

}


icmp6_dest_unreach (struct pbuf * p, icmp6_dur_code c)
{
  <bb 2> :
  _1 = (unsigned char) c;
  icmp6_send_response (p, _1, 0, 1);
  return;

}


icmp6_input (struct pbuf * p, struct netif * inp)
{
  const struct ip6_addr_t * reply_src;
  struct pbuf * r;
  struct icmp6_hdr * icmp6hdr;

  <bb 2> :
  _1 = lwip_stats.icmp6.recv;
  _2 = _1 + 1;
  lwip_stats.icmp6.recv = _2;
  _3 = p->len;
  if (_3 <= 7)
    goto <bb 3>; [INV]
  else
    goto <bb 4>; [INV]

  <bb 3> :
  pbuf_free (p);
  _4 = lwip_stats.icmp6.lenerr;
  _5 = _4 + 1;
  lwip_stats.icmp6.lenerr = _5;
  _6 = lwip_stats.icmp6.drop;
  _7 = _6 + 1;
  lwip_stats.icmp6.drop = _7;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 19>; [INV]

  <bb 4> :
  icmp6hdr = p->payload;
  _8 = p->tot_len;
  _9 = ip6_chksum_pseudo (p, 58, _8, &ip_data.current_iphdr_src.u_addr.ip6, &ip_data.current_iphdr_dest.u_addr.ip6);
  if (_9 != 0)
    goto <bb 5>; [INV]
  else
    goto <bb 6>; [INV]

  <bb 5> :
  pbuf_free (p);
  _10 = lwip_stats.icmp6.chkerr;
  _11 = _10 + 1;
  lwip_stats.icmp6.chkerr = _11;
  _12 = lwip_stats.icmp6.drop;
  _13 = _12 + 1;
  lwip_stats.icmp6.drop = _13;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 19>; [INV]

  <bb 6> :
  _14 = icmp6hdr->type;
  _15 = (int) _14;
  switch (_15) <default: <L20> [INV], case 2: <L4> [INV], case 128: <L13> [INV], case 130 ... 132: <L10> [INV], case 133: <L9> [INV], case 134 ... 137: <L4> [INV]>

  <bb 7> :
<L4>:
  nd6_input (p, inp);
  goto <bb 19>; [INV]

  <bb 8> :
<L9>:
  goto <bb 18>; [INV]

  <bb 9> :
<L10>:
  mld6_input (p, inp);
  goto <bb 19>; [INV]

  <bb 10> :
<L13>:
  _16 = ip_data.current_iphdr_dest.u_addr.ip6.addr[0];
  _17 = _16 & 255;
  if (_17 == 255)
    goto <bb 11>; [INV]
  else
    goto <bb 12>; [INV]

  <bb 11> :
  pbuf_free (p);
  _18 = lwip_stats.icmp6.drop;
  _19 = _18 + 1;
  lwip_stats.icmp6.drop = _19;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 19>; [INV]

  <bb 12> :
  _20 = p->tot_len;
  r = pbuf_alloc (54, _20, 640);
  if (r == 0B)
    goto <bb 13>; [INV]
  else
    goto <bb 14>; [INV]

  <bb 13> :
  pbuf_free (p);
  _21 = lwip_stats.icmp6.memerr;
  _22 = _21 + 1;
  lwip_stats.icmp6.memerr = _22;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 19>; [INV]

  <bb 14> :
  _23 = pbuf_copy (r, p);
  if (_23 != 0)
    goto <bb 15>; [INV]
  else
    goto <bb 16>; [INV]

  <bb 15> :
  pbuf_free (p);
  pbuf_free (r);
  _24 = lwip_stats.icmp6.err;
  _25 = _24 + 1;
  lwip_stats.icmp6.err = _25;
  // predicted unlikely by early return (on trees) predictor.
  goto <bb 19>; [INV]

  <bb 16> :
  reply_src = &ip_data.current_iphdr_dest.u_addr.ip6;
  _26 = r->payload;
  MEM[(struct icmp6_echo_hdr *)_26].type = 129;
  _27 = r->payload;
  MEM[(struct icmp6_echo_hdr *)_27].chksum = 0;
  _28 = r->tot_len;
  _29 = r->payload;
  _30 = ip6_chksum_pseudo (r, 58, _28, reply_src, &ip_data.current_iphdr_src.u_addr.ip6);
  MEM[(struct icmp6_echo_hdr *)_29].chksum = _30;
  _31 = lwip_stats.icmp6.xmit;
  _32 = _31 + 1;
  lwip_stats.icmp6.xmit = _32;
  ip6_output_if (r, reply_src, &ip_data.current_iphdr_src.u_addr.ip6, 255, 0, 58, inp);
  pbuf_free (r);
  goto <bb 18>; [INV]

  <bb 17> :
<L20>:
  _33 = lwip_stats.icmp6.proterr;
  _34 = _33 + 1;
  lwip_stats.icmp6.proterr = _34;
  _35 = lwip_stats.icmp6.drop;
  _36 = _35 + 1;
  lwip_stats.icmp6.drop = _36;

  <bb 18> :
  pbuf_free (p);

  <bb 19> :
<L22>:
  return;

}


